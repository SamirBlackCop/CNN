{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = \"D:\\\\DATASETS\\\\Dogs vs Cats\\\\archive.zip\"\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(\"D:\\\\DATASETS\\\\Dogs vs Cats\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir =\"D:\\\\DATASETS\\\\Dogs vs Cats\\\\datasets\"\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory with our training cat pic\n",
    "train_cat_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with our training Dogs pic\n",
    "train_dog_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat pic\n",
    "test_cat_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with our validation dogs pic\n",
    "test_dog_dir = os.path.join(validation_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cats images : 1080\n",
      "total training dogs images : 1080\n",
      "total validation cats images : 421\n",
      "total validation dogs images : 421\n"
     ]
    }
   ],
   "source": [
    "print(\"total training cats images : {}\".format(len(os.listdir(train_cat_dir))))\n",
    "print(\"total training dogs images : {}\".format(len(os.listdir(train_dog_dir))))\n",
    "print(\"total validation cats images : {}\".format(len(os.listdir(test_cat_dir))))\n",
    "print(\"total validation dogs images : {}\".format(len(os.listdir(test_dog_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "img_input  = layers.Input(shape=(150,150,3))\n",
    "X = layers.Conv2D(16,3, activation='relu')(img_input)\n",
    "X = layers.MaxPooling2D(2)(X)\n",
    "\n",
    "\n",
    "X = layers.Conv2D(32,3, activation='relu')(X)\n",
    "X = layers.MaxPooling2D(2)(X)\n",
    "\n",
    "X = layers.Conv2D(64,3, activation='relu')(X)\n",
    "X = layers.MaxPooling2D(2)(X)\n",
    "\n",
    "\n",
    "X = layers.Flatten()(X)\n",
    "\n",
    "X = layers.Dense(512, activation='relu')(X)\n",
    "\n",
    "output = layers.Dense(1, activation='sigmoid')(X)\n",
    "\n",
    "\n",
    "\n",
    "# Create Model\n",
    "# input = input feature map\n",
    "# output = input feature map + stacked convolution/MaxPooling layers + Fully\n",
    "# Connected layers + sigmoid Output layers\n",
    "\n",
    "model = Model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               9470464   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 9,494,561\n",
      "Trainable params: 9,494,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=RMSprop(lr=0.001),\n",
    "             metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2160 images belonging to 2 classes.\n",
      "Found 842 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image DataGenerator to prevent Overfitting\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# All Images wil be rescaled by 1./255\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  #This is source directory for training images\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sdasz\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 - 38s - loss: 0.7914 - acc: 0.5655 - val_loss: 0.6553 - val_acc: 0.6342\n",
      "Epoch 2/2\n",
      "100/100 - 24s - loss: 0.6423 - acc: 0.6440\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=100,\n",
    "                             epochs=2,\n",
    "    \n",
    "                             validation_data = validation_generator,\n",
    "                             validation_steps = 50,\n",
    "                             verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img(\"C:\\\\Users\\\\Sdasz\\\\Downloads\\\\pexels-orlando-allo-3658120.jpg\", target_size=(150,150))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = model.predict(test_image)\n",
    "train_generator.class_indices\n",
    "\n",
    "if result[0][0] ==1:\n",
    "    prediction = 'dog'\n",
    "    print(prediction)\n",
    "    \n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## another way to find the o/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from zipfile import ZipFile\n",
    "file_name  =\"D:\\\\DATASETS\\\\Dogs vs Cats\\\\archive.zip\"\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    zip.extractall()\n",
    "    print('finished')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install zip-files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing CNN\n",
    "cnn_classifier = Sequential()\n",
    "\n",
    "# 1st step convolution\n",
    "cnn_classifier.add(Conv2D(32,3, 3, input_shape=(64,64,3), activation ='relu')) # 16 is number of filter or feature detecter & 3,3 is the matrix of filter\n",
    "\"\"\"we use relu activation function to eliminate linearity in given feature input\"\"\"\n",
    "\n",
    "# 2nd step pooling\n",
    "cnn_classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Add a Second layer of Convolution layer\n",
    "cnn_classifier.add(Conv2D(16, 3, 3, activation ='relu')) # 16 is number of filter or feature detecter & 3,3 is the matrix of filter\n",
    "cnn_classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# 3rd Step Flatteinigng\n",
    "cnn_classifier.add(Flatten())\n",
    "\n",
    "# 4th Step Full Connention\n",
    "cnn_classifier.add(Dense(units=128, activation='relu'))\n",
    "cnn_classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling The CNN\n",
    "cnn_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pip install np-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import np_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras ImageData Generator\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.datasets import cifar10\n",
    "\n",
    "\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = np_utils.to_categorical(y_train, None)\n",
    "y_test = np_utils.to_categorical(y_test, None)\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(x_train)\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "cnn_classifier.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=1)\n",
    "# here's a more \"manual\" example\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"for e in range(1):\n",
    "    #print(2, e)\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
    "        model.fit(x_batch, y_batch)\n",
    "        batches += 1\n",
    "        if batches >= len(x_train) / 32:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img(\"C:\\\\Users\\\\Sdasz\\\\Downloads\\\\pexels-orlando-allo-3658120.jpg\", target_size=(150,150))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = model.predict(test_image)\n",
    "train_generator.class_indices\n",
    "\n",
    "if result[0][0] ==1:\n",
    "    prediction = 'dog'\n",
    "    print(prediction)\n",
    "    \n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
